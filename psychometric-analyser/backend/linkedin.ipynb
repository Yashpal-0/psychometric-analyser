{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcB_vdh_Pi-h",
        "outputId": "647d5954-c092-43d2-bec0-5069850bddf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/yash/anaconda3/lib/python3.11/site-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /home/yash/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/yash/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/yash/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/yash/anaconda3/lib/python3.11/site-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/yash/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/yash/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: requests in /home/yash/anaconda3/lib/python3.11/site-packages (from transformers) (2.29.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/yash/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/yash/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /home/yash/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/yash/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/yash/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/yash/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/yash/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/yash/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "K431iv4zhPqP",
        "outputId": "2402f371-e271-47f1-ff95-1f7f884347b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-29 03:49:00.033893: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-10-29 03:49:00.076251: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-10-29 03:49:00.315094: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-29 03:49:00.315221: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-29 03:49:00.315924: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-29 03:49:00.414079: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-10-29 03:49:00.417166: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-29 03:49:03.565951: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'1.24.3'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sea\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "np.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "JP8t3uDZN1tQ",
        "outputId": "7395e884-c963-407b-f5b4-922736257bf9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "      <th>Q3</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5</th>\n",
              "      <th>Role</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>&lt;start1&gt; proactively initiating conversations ...</td>\n",
              "      <td>&lt;start2&gt; rejection is an opportunity for self-...</td>\n",
              "      <td>&lt;start3&gt; to maintain creativity and organizati...</td>\n",
              "      <td>&lt;start4&gt; i made sure the group felt heard, off...</td>\n",
              "      <td>&lt;start5&gt; i'll be an adaptable and proactive te...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>&lt;start1&gt; i often find creative inspiration whe...</td>\n",
              "      <td>&lt;start2&gt; i'm known to be persistent and adapti...</td>\n",
              "      <td>&lt;start3&gt; i stay inspired by exploring unconven...</td>\n",
              "      <td>&lt;start4&gt; i emphasized the innovation and poten...</td>\n",
              "      <td>&lt;start5&gt; i'd respect team members' expertise, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>&lt;start1&gt; i'm comfortable when others take the ...</td>\n",
              "      <td>&lt;start2&gt; rejection in it prompts me to persist...</td>\n",
              "      <td>&lt;start3&gt; creativity flourishes under pressure....</td>\n",
              "      <td>&lt;start4&gt; my approach was to use plain language...</td>\n",
              "      <td>&lt;start5&gt; i'd be attentive, support my team's g...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>&lt;start1&gt; i'm more of a listener in social situ...</td>\n",
              "      <td>&lt;start2&gt; in it, rejection inspires me to persi...</td>\n",
              "      <td>&lt;start3&gt; i maintain a structured approach with...</td>\n",
              "      <td>&lt;start4&gt; i shared my proposal by simplifying t...</td>\n",
              "      <td>&lt;start5&gt; steering a cross-functional team succ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&lt;start1&gt; in social situations, i enjoy approac...</td>\n",
              "      <td>&lt;start2&gt; i view rejection as feedback. i persi...</td>\n",
              "      <td>&lt;start3&gt; creativity is enhanced through contin...</td>\n",
              "      <td>&lt;start4&gt; i maintained eye contact, conveyed en...</td>\n",
              "      <td>&lt;start5&gt; i'm excited to collaborate closely wi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>&lt;start1&gt; i often find creative inspiration whe...</td>\n",
              "      <td>&lt;start2&gt; i'd approach rejection as a challenge...</td>\n",
              "      <td>&lt;start3&gt; i use tight deadlines as a chance to ...</td>\n",
              "      <td>&lt;start4&gt; i explained my idea using everyday co...</td>\n",
              "      <td>&lt;start5&gt; i'd work alongside the team, adhere t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>&lt;start1&gt; i'm more comfortable when others init...</td>\n",
              "      <td>&lt;start2&gt; i'd view rejection as a chance to enh...</td>\n",
              "      <td>&lt;start3&gt; i stay organized using comprehensive ...</td>\n",
              "      <td>&lt;start4&gt; i started with a relatable analogy to...</td>\n",
              "      <td>&lt;start5&gt; i'd work in sync with the team, meet ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>&lt;start1&gt; i'm comfortable with both being appro...</td>\n",
              "      <td>&lt;start2&gt; rejection or failure is part of the i...</td>\n",
              "      <td>&lt;start3&gt; tight deadlines spark my technical cr...</td>\n",
              "      <td>&lt;start4&gt; i shared relevant technical research ...</td>\n",
              "      <td>&lt;start5&gt; i'd stay organized, document my work,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>&lt;start1&gt; i thrive in initiating conversations....</td>\n",
              "      <td>&lt;start2&gt; rejection pushes me to keep evolving ...</td>\n",
              "      <td>&lt;start3&gt; i draw inspiration from the sense of ...</td>\n",
              "      <td>&lt;start4&gt; i tailored my presentation to the gro...</td>\n",
              "      <td>&lt;start5&gt; i'll bring my best to the team, activ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>&lt;start1&gt; i enjoy being approached by others, a...</td>\n",
              "      <td>&lt;start2&gt; rejection prompts me to persistently ...</td>\n",
              "      <td>&lt;start3&gt; to maintain both organization and cre...</td>\n",
              "      <td>&lt;start4&gt; i engaged in hands-on demonstrations,...</td>\n",
              "      <td>&lt;start5&gt; nurturing a cross-functional team req...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Q1  \\\n",
              "6   <start1> proactively initiating conversations ...   \n",
              "71  <start1> i often find creative inspiration whe...   \n",
              "86  <start1> i'm comfortable when others take the ...   \n",
              "88  <start1> i'm more of a listener in social situ...   \n",
              "7   <start1> in social situations, i enjoy approac...   \n",
              "..                                                ...   \n",
              "62  <start1> i often find creative inspiration whe...   \n",
              "50  <start1> i'm more comfortable when others init...   \n",
              "70  <start1> i'm comfortable with both being appro...   \n",
              "42  <start1> i thrive in initiating conversations....   \n",
              "77  <start1> i enjoy being approached by others, a...   \n",
              "\n",
              "                                                   Q2  \\\n",
              "6   <start2> rejection is an opportunity for self-...   \n",
              "71  <start2> i'm known to be persistent and adapti...   \n",
              "86  <start2> rejection in it prompts me to persist...   \n",
              "88  <start2> in it, rejection inspires me to persi...   \n",
              "7   <start2> i view rejection as feedback. i persi...   \n",
              "..                                                ...   \n",
              "62  <start2> i'd approach rejection as a challenge...   \n",
              "50  <start2> i'd view rejection as a chance to enh...   \n",
              "70  <start2> rejection or failure is part of the i...   \n",
              "42  <start2> rejection pushes me to keep evolving ...   \n",
              "77  <start2> rejection prompts me to persistently ...   \n",
              "\n",
              "                                                   Q3  \\\n",
              "6   <start3> to maintain creativity and organizati...   \n",
              "71  <start3> i stay inspired by exploring unconven...   \n",
              "86  <start3> creativity flourishes under pressure....   \n",
              "88  <start3> i maintain a structured approach with...   \n",
              "7   <start3> creativity is enhanced through contin...   \n",
              "..                                                ...   \n",
              "62  <start3> i use tight deadlines as a chance to ...   \n",
              "50  <start3> i stay organized using comprehensive ...   \n",
              "70  <start3> tight deadlines spark my technical cr...   \n",
              "42  <start3> i draw inspiration from the sense of ...   \n",
              "77  <start3> to maintain both organization and cre...   \n",
              "\n",
              "                                                   Q4  \\\n",
              "6   <start4> i made sure the group felt heard, off...   \n",
              "71  <start4> i emphasized the innovation and poten...   \n",
              "86  <start4> my approach was to use plain language...   \n",
              "88  <start4> i shared my proposal by simplifying t...   \n",
              "7   <start4> i maintained eye contact, conveyed en...   \n",
              "..                                                ...   \n",
              "62  <start4> i explained my idea using everyday co...   \n",
              "50  <start4> i started with a relatable analogy to...   \n",
              "70  <start4> i shared relevant technical research ...   \n",
              "42  <start4> i tailored my presentation to the gro...   \n",
              "77  <start4> i engaged in hands-on demonstrations,...   \n",
              "\n",
              "                                                   Q5  Role  \n",
              "6   <start5> i'll be an adaptable and proactive te...     1  \n",
              "71  <start5> i'd respect team members' expertise, ...     0  \n",
              "86  <start5> i'd be attentive, support my team's g...     0  \n",
              "88  <start5> steering a cross-functional team succ...     0  \n",
              "7   <start5> i'm excited to collaborate closely wi...     1  \n",
              "..                                                ...   ...  \n",
              "62  <start5> i'd work alongside the team, adhere t...     1  \n",
              "50  <start5> i'd work in sync with the team, meet ...     1  \n",
              "70  <start5> i'd stay organized, document my work,...     0  \n",
              "42  <start5> i'll bring my best to the team, activ...     1  \n",
              "77  <start5> nurturing a cross-functional team req...     0  \n",
              "\n",
              "[100 rows x 6 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('./psychometric.csv')\n",
        "for col in df.columns:\n",
        "    df[col] = df[col].map(lambda x : x.lower())\n",
        "df = df.sample(frac=1.0)\n",
        "\n",
        "df['Role'] = (df['Role'] == 'sales').astype(np.int32)\n",
        "df = df.sample(frac=1.0)\n",
        "\n",
        "for i in range(1, 6):\n",
        "    df[f'Q{i}'] = df[f'Q{i}'].map(lambda x : f'<start{i}> {x} </end{i}>')\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pls_M75QAaY",
        "outputId": "994c2bc0-30c9-4563-aa7a-4e32280adf79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([\"<start1> i excel at initiating conversations, a key part of my role. it's essential for building rapport and understanding clients, helping me connect and identify opportunities effectively. </end1>\",\n",
              "       '<start2> rejection pushes me to improve. i persist, adapt, and stay committed to finding the best path to success. </end2>',\n",
              "       '<start3> tight deadlines serve as a reminder of the difference my work can make. i stay organized with time blocks and tap into my creative problem-solving skills. </end3>',\n",
              "       '<start4> i presented my proposal by opening with a captivating story that engaged the audience emotionally. i focused on how the idea would benefit them personally. </end4>',\n",
              "       \"<start5> i'll collaborate closely with team members, share my ideas, and support their efforts to reach our goal. i'll stay open to learning from experienced colleagues and adapt to the team's needs. </end5>\"],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.loc[0].values[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "epEk9exCMIQF"
      },
      "outputs": [],
      "source": [
        "# X = []\n",
        "\n",
        "# for i in range(len(df)):\n",
        "#     x = \"\"\n",
        "#     for j in range(6):\n",
        "#         x += f\"<start{j}> {df.iloc[i, j]} <end{j}> \"\n",
        "#     X.append(x)\n",
        "\n",
        "# X[0]\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(len(df)):\n",
        "    X.extend(df.loc[i].values[:-1])\n",
        "    y.extend([df.loc[i].values[-1]] * 5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZanVwXpTkvoc",
        "outputId": "ecddf65e-29f8-45b6-9683-e60c8a30ea46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X vocab: 1296\n"
          ]
        }
      ],
      "source": [
        "# X, y = df['Description'].values, df['Outcome'].values\n",
        "\n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(X)\n",
        "x_vocab = len(x_tokenizer.word_index) + 1\n",
        "print(\"X vocab:\", x_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VmoZs7pRfTzz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(X, y, test_size = 0.1, stratify = y)\n",
        "# train_x.shape, val_x.shape, train_y.shape, val_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "pcBka78ZNGLE",
        "outputId": "a969e56f-cc22-426b-c9d1-6e71ff87ab52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: ylabel='Count'>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "lens = []\n",
        "for x in X:\n",
        "    lens.append(len(x.split(' ')))\n",
        "\n",
        "sea.histplot(lens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xB7zYixKPW8v"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "632d76e162b14bd897b39c97e294f832",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6222366be2674431bd349cba0b145414",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1705f522b9354c8fb7b959b607cee596",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c0d90f19a50448595994f8601fc1871",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-29 03:49:56.230472: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "train_encodings = tokenizer(list(train_x), max_length = 40, padding=\"max_length\", truncation=True)\n",
        "val_encodings = tokenizer(list(val_x), max_length = 40, padding=\"max_length\", truncation=True)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    train_y\n",
        ")).batch(BATCH_SIZE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(val_encodings),\n",
        "    val_y\n",
        ")).batch(BATCH_SIZE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ9hSYiMVocC",
        "outputId": "306dce69-5d45-4320-c963-12c8bbf7223e"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nNo module named 'keras.engine'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1172\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1172\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m module_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m   1173\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39m_gcd_import(name[level:], package, level)\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1206\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1149\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/bert/modeling_tf_bert.py:38\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_tf_outputs\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     TFBaseModelOutputWithPastAndCrossAttentions,\n\u001b[1;32m     29\u001b[0m     TFBaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     TFTokenClassifierOutput,\n\u001b[1;32m     37\u001b[0m )\n\u001b[0;32m---> 38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_tf_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     TFCausalLanguageModelingLoss,\n\u001b[1;32m     40\u001b[0m     TFMaskedLanguageModelingLoss,\n\u001b[1;32m     41\u001b[0m     TFModelInputType,\n\u001b[1;32m     42\u001b[0m     TFMultipleChoiceLoss,\n\u001b[1;32m     43\u001b[0m     TFNextSentencePredictionLoss,\n\u001b[1;32m     44\u001b[0m     TFPreTrainedModel,\n\u001b[1;32m     45\u001b[0m     TFQuestionAnsweringLoss,\n\u001b[1;32m     46\u001b[0m     TFSequenceClassificationLoss,\n\u001b[1;32m     47\u001b[0m     TFTokenClassificationLoss,\n\u001b[1;32m     48\u001b[0m     get_initializer,\n\u001b[1;32m     49\u001b[0m     keras_serializable,\n\u001b[1;32m     50\u001b[0m     unpack_inputs,\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m shape_list, stable_softmax\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:70\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n\u001b[0;32m---> 70\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m data_adapter\n\u001b[1;32m     71\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras_tensor\u001b[39;00m \u001b[39mimport\u001b[39;00m KerasTensor\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.engine'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/media/D49EC8FA9EC8D5E0/Megathon/psychometric-analyser/backend/linkedin.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/D49EC8FA9EC8D5E0/Megathon/psychometric-analyser/backend/linkedin.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m num_classes \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/D49EC8FA9EC8D5E0/Megathon/psychometric-analyser/backend/linkedin.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m TFAutoModelForSequenceClassification\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/D49EC8FA9EC8D5E0/Megathon/psychometric-analyser/backend/linkedin.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m TFAutoModelForSequenceClassification\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/D49EC8FA9EC8D5E0/Megathon/psychometric-analyser/backend/linkedin.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbert-base-cased\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/D49EC8FA9EC8D5E0/Megathon/psychometric-analyser/backend/linkedin.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     num_labels \u001b[39m=\u001b[39m num_classes,\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/D49EC8FA9EC8D5E0/Megathon/psychometric-analyser/backend/linkedin.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     id2label \u001b[39m=\u001b[39m {\u001b[39m1\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGood\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mBad\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/D49EC8FA9EC8D5E0/Megathon/psychometric-analyser/backend/linkedin.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     label2id \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mGood\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mBad\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m0\u001b[39m},\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/D49EC8FA9EC8D5E0/Megathon/psychometric-analyser/backend/linkedin.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     output_attentions \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/D49EC8FA9EC8D5E0/Megathon/psychometric-analyser/backend/linkedin.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/D49EC8FA9EC8D5E0/Megathon/psychometric-analyser/backend/linkedin.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     loss \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/D49EC8FA9EC8D5E0/Megathon/psychometric-analyser/backend/linkedin.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     optimizer \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate \u001b[39m=\u001b[39m \u001b[39m1e-5\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/D49EC8FA9EC8D5E0/Megathon/psychometric-analyser/backend/linkedin.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/D49EC8FA9EC8D5E0/Megathon/psychometric-analyser/backend/linkedin.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:466\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    463\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39mmodel_args, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    464\u001b[0m     )\n\u001b[1;32m    465\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m--> 466\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[1;32m    467\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    468\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39mmodel_args, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    469\u001b[0m     )\n\u001b[1;32m    470\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    471\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    472\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    473\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:360\u001b[0m, in \u001b[0;36m_get_model_class\u001b[0;34m(config, model_mapping)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_model_class\u001b[39m(config, model_mapping):\n\u001b[0;32m--> 360\u001b[0m     supported_models \u001b[39m=\u001b[39m model_mapping[\u001b[39mtype\u001b[39m(config)]\n\u001b[1;32m    361\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(supported_models, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    362\u001b[0m         \u001b[39mreturn\u001b[39;00m supported_models\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:598\u001b[0m, in \u001b[0;36m_LazyAutoMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39mif\u001b[39;00m model_type \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_mapping:\n\u001b[1;32m    597\u001b[0m     model_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_mapping[model_type]\n\u001b[0;32m--> 598\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_attr_from_module(model_type, model_name)\n\u001b[1;32m    600\u001b[0m \u001b[39m# Maybe there was several model types associated with this config.\u001b[39;00m\n\u001b[1;32m    601\u001b[0m model_types \u001b[39m=\u001b[39m [k \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config_mapping\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v \u001b[39m==\u001b[39m key\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m]\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:612\u001b[0m, in \u001b[0;36m_LazyAutoMapping._load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[39mif\u001b[39;00m module_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules:\n\u001b[1;32m    611\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules[module_name] \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtransformers.models\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 612\u001b[0m \u001b[39mreturn\u001b[39;00m getattribute_from_module(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules[module_name], attr)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:557\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(attr, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    556\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m attr)\n\u001b[0;32m--> 557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(module, attr):\n\u001b[1;32m    558\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(module, attr)\n\u001b[1;32m    559\u001b[0m \u001b[39m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39m# object at the top level.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1162\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(name)\n\u001b[1;32m   1161\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m-> 1162\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   1163\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1164\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1174\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m module_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m   1173\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1175\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1176\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1177\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nNo module named 'keras.engine'"
          ]
        }
      ],
      "source": [
        "num_classes = 2\n",
        "\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-cased\",\n",
        "    num_labels = num_classes,\n",
        "    id2label = {1:'Good', 0:\"Bad\"},\n",
        "    label2id = {\"Good\":1, 'Bad':0},\n",
        "    output_attentions = True)\n",
        "\n",
        "model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 1e-5),\n",
        "    metrics = ['accuracy'])\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyhLNjRndBQ2",
        "outputId": "105c1f75-f2c3-464d-f758-da0825a4e4ac"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/media/D49EC8FA9EC8D5E0/IIITH/Monsoon_2023(Sem_V)/Statistical Methods in AI/Assignment 3/.conda/bin/python' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /media/D49EC8FA9EC8D5E0/IIITH/Monsoon_2023(Sem_V)/Statistical Methods in AI/Assignment 3/.conda ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "for layer in model.layers:\n",
        "    print(layer, layer.trainable)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY-wIcIAdwMl",
        "outputId": "7c11153f-ee67-4a62-a24e-8035b513d554"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/media/D49EC8FA9EC8D5E0/IIITH/Monsoon_2023(Sem_V)/Statistical Methods in AI/Assignment 3/.conda/bin/python' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /media/D49EC8FA9EC8D5E0/IIITH/Monsoon_2023(Sem_V)/Statistical Methods in AI/Assignment 3/.conda ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "history = model.fit(train_dataset,\n",
        "          epochs = EPOCHS,\n",
        "          validation_data = val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufz1Etoadl_a",
        "outputId": "e1a0445f-0a2e-4c55-9e98-cb561f7e08e3"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/media/D49EC8FA9EC8D5E0/IIITH/Monsoon_2023(Sem_V)/Statistical Methods in AI/Assignment 3/.conda/bin/python' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /media/D49EC8FA9EC8D5E0/IIITH/Monsoon_2023(Sem_V)/Statistical Methods in AI/Assignment 3/.conda ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, top_k = num_classes)\n",
        "pred1 = pipe(\"<start1>I excel at initiating conversations, a key part of my role. It's essential for building rapport and understanding clients, helping me connect and identify opportunities effectively.</end1>\")\n",
        "\n",
        "print(pred1[0][:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3HgB2DXy8m1"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/media/D49EC8FA9EC8D5E0/IIITH/Monsoon_2023(Sem_V)/Statistical Methods in AI/Assignment 3/.conda/bin/python' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /media/D49EC8FA9EC8D5E0/IIITH/Monsoon_2023(Sem_V)/Statistical Methods in AI/Assignment 3/.conda ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "input = [\"I excel in technology but am reluctant to seek help or collaborate. My ego is my guiding force, overshadowing any potential for growth through collective efforts\"]\n",
        "\n",
        "input_ids = tokenizer.encode(input[0], add_special_tokens=True, max_length=60, padding='max_length', return_tensors='tf')\n",
        "\n",
        "# test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    # dict(tokenizer(input, padding=\"max_length\", truncation=True, max_length=40)),\n",
        "# )).batch(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ghN1M2E1O1g",
        "outputId": "ca43bfd1-a163-4f6b-9319-f420a3af3737"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/media/D49EC8FA9EC8D5E0/IIITH/Monsoon_2023(Sem_V)/Statistical Methods in AI/Assignment 3/.conda/bin/python' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /media/D49EC8FA9EC8D5E0/IIITH/Monsoon_2023(Sem_V)/Statistical Methods in AI/Assignment 3/.conda ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "outputs = model(input_ids)\n",
        "pred = outputs[0]\n",
        "\n",
        "tf.math.exp(pred)/tf.reduce_sum(tf.math.exp(pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGQvpEs311Nl",
        "outputId": "44e8444f-2d5f-4694-9a6d-fb6f98eaf1e1"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/media/D49EC8FA9EC8D5E0/IIITH/Monsoon_2023(Sem_V)/Statistical Methods in AI/Assignment 3/.conda/bin/python' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /media/D49EC8FA9EC8D5E0/IIITH/Monsoon_2023(Sem_V)/Statistical Methods in AI/Assignment 3/.conda ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "for head in range(0, 12):\n",
        "    sum_attention_scores = tf.reduce_sum(outputs[1][0][0][head], axis=-1)\n",
        "    max_attention_token_index = tf.math.argmax(sum_attention_scores)\n",
        "\n",
        "    # for token in max_attention_token_index[:5]:\n",
        "    word = tokenizer.convert_ids_to_tokens([input_ids[0][max_attention_token_index]])\n",
        "    print(word)\n",
        "\n",
        "# print(\"Token with maximum summed attention:\", max_attention_token, max_attention_token_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSN2YzURB1FY"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/media/D49EC8FA9EC8D5E0/IIITH/Monsoon_2023(Sem_V)/Statistical Methods in AI/Assignment 3/.conda/bin/python' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /media/D49EC8FA9EC8D5E0/IIITH/Monsoon_2023(Sem_V)/Statistical Methods in AI/Assignment 3/.conda ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
